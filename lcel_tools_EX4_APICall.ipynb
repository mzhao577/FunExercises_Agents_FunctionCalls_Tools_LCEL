{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b815ef73",
   "metadata": {},
   "source": [
    "# Tools and Routing\n",
    "\n",
    "Previously, we showed how functions can be supplied to OpenAI models. \n",
    "\n",
    "They can be used to specify an output schema required for tasks (e.g., extraction, tagging) or for an API. \n",
    "\n",
    "Tools are more general and are a central concept in [LLM agents](https://python.langchain.com/docs/use_cases/more/agents/).\n",
    "\n",
    "Often times, tools wrap APIs so that LLMs can easily access them. \n",
    "\n",
    "We can define tools (e.g., from functions) as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8988e16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "#!pip install python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "print(os.environ[\"OPENAI_API_KEY\"]),\n",
    "OPENAI_API_KEY=os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecac1233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.2.15\n",
      "langchain-community==0.2.13\n",
      "langchain-core==0.2.41\n",
      "langchain-openai==0.1.23\n",
      "langchain-text-splitters==0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep langchain\n",
    "#langchain==0.3.0\n",
    "#langchain-community==0.3.0\n",
    "#langchain-core==0.3.5\n",
    "#langchain-openai==0.2.0\n",
    "#langchain-text-splitters==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4669d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain-openai==0.1.23\n",
      "openai==1.47.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep openai\n",
    "#langchain-openai==0.2.0\n",
    "#openai==1.47.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd850e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openapi-schema-pydantic==1.2.4\n",
      "pydantic==1.10.8\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep pydantic\n",
    "#pydantic==2.9.2\n",
    "#pydantic-settings==2.5.2\n",
    "#pydantic_core==2.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec49dd9e-b3e2-42b6-b203-2faa1206b2bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db928d-97f8-4389-91f1-6354824a9208",
   "metadata": {},
   "source": [
    "# Querying an API from a OpenAPI specfiction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac11dc9-457a-4744-aadb-3df7f78c24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install openapi_schema_pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5edfda-6b4d-4281-9278-3b9c22fa47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "from langchain.utilities.openapi import OpenAPISpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd77787-8e59-451e-9e49-0ecd694b369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "{\n",
    "  \"openapi\": \"3.0.0\",\n",
    "  \"info\": {\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"title\": \"Swagger Petstore\",\n",
    "    \"license\": {\n",
    "      \"name\": \"MIT\"\n",
    "    }\n",
    "  },\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"url\": \"http://petstore.swagger.io/v1\"\n",
    "    }\n",
    "  ],\n",
    "  \"paths\": {\n",
    "    \"/pets\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"List all pets\",\n",
    "        \"operationId\": \"listPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"limit\",\n",
    "            \"in\": \"query\",\n",
    "            \"description\": \"How many items to return at one time (max 100)\",\n",
    "            \"required\": false,\n",
    "            \"schema\": {\n",
    "              \"type\": \"integer\",\n",
    "              \"maximum\": 100,\n",
    "              \"format\": \"int32\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"A paged array of pets\",\n",
    "            \"headers\": {\n",
    "              \"x-next\": {\n",
    "                \"description\": \"A link to the next page of responses\",\n",
    "                \"schema\": {\n",
    "                  \"type\": \"string\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pets\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"post\": {\n",
    "        \"summary\": \"Create a pet\",\n",
    "        \"operationId\": \"createPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"201\": {\n",
    "            \"description\": \"Null response\"\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"/pets/{petId}\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"Info for a specific pet\",\n",
    "        \"operationId\": \"showPetById\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"petId\",\n",
    "            \"in\": \"path\",\n",
    "            \"required\": true,\n",
    "            \"description\": \"The id of the pet to retrieve\",\n",
    "            \"schema\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"Expected response to a valid request\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pet\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"schemas\": {\n",
    "      \"Pet\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"id\",\n",
    "          \"name\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"id\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int64\"\n",
    "          },\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"tag\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Pets\": {\n",
    "        \"type\": \"array\",\n",
    "        \"maxItems\": 100,\n",
    "        \"items\": {\n",
    "          \"$ref\": \"#/components/schemas/Pet\"\n",
    "        }\n",
    "      },\n",
    "      \"Error\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"code\",\n",
    "          \"message\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"code\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int32\"\n",
    "          },\n",
    "          \"message\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8161187e-8703-44e0-a280-354f5581337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute 'parse_obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAPISpec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lcel_apicall/lib/python3.12/site-packages/langchain_community/utilities/openapi.py:227\u001b[0m, in \u001b[0;36mOpenAPISpec.from_text\u001b[0;34m(cls, text)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m    226\u001b[0m     spec_dict \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(text)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_spec_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lcel_apicall/lib/python3.12/site-packages/langchain_community/utilities/openapi.py:218\u001b[0m, in \u001b[0;36mOpenAPISpec.from_spec_dict\u001b[0;34m(cls, spec_dict)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_spec_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, spec_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OpenAPISpec:\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get an OpenAPI spec from a dict.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lcel_apicall/lib/python3.12/site-packages/langchain_community/utilities/openapi.py:202\u001b[0m, in \u001b[0;36mOpenAPISpec.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_alert_unsupported_spec(obj)\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m(obj)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# We are handling possibly misconfigured specs and\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# want to do a best-effort job to get a reasonable interface out of it.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(obj)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute 'parse_obj'"
     ]
    }
   ],
   "source": [
    "spec = OpenAPISpec.from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0e76f98-d398-43a1-b07a-84825039e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c61b3be-28af-4c3f-9d15-fe7eea5a940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'listPets',\n",
       "  'description': 'List all pets',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'params': {'type': 'object',\n",
       "     'properties': {'limit': {'type': 'integer',\n",
       "       'maximum': 100.0,\n",
       "       'schema_format': 'int32',\n",
       "       'description': 'How many items to return at one time (max 100)'}},\n",
       "     'required': []}}}},\n",
       " {'name': 'createPets',\n",
       "  'description': 'Create a pet',\n",
       "  'parameters': {'type': 'object', 'properties': {}}},\n",
       " {'name': 'showPetById',\n",
       "  'description': 'Info for a specific pet',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'path_params': {'type': 'object',\n",
       "     'properties': {'petId': {'type': 'string',\n",
       "       'description': 'The id of the pet to retrieve'}},\n",
       "     'required': ['petId']}}}}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a22c864f-c1f4-4ce1-964b-65c95b796b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7e176e04-7f02-4a24-be61-ce4ce8b0ab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'listPets', 'arguments': '{\\n  \"params\": {\\n    \"limit\": 3\\n  }\\n}'}})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what are three pet names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e04983e6-e3a2-4dd7-95b4-2210688725c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'showPetById', 'arguments': '{\\n  \"path_params\": {\\n    \"petId\": \"43\"\\n  }\\n}'}})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"tell me about pet with id 43\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f961e0-70a1-41e4-95d6-fc5af42b3ff2",
   "metadata": {},
   "source": [
    "### Routing\n",
    "\n",
    "In lesson 3, we show an example of function calling deciding between two candidate functions.\n",
    "\n",
    "Given our tools above, let's format these as OpenAI functions and show this same behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9dff4af-63eb-45c6-b669-e05286819019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "functions = [format_tool_to_openai_function(f) for f in [search_wikipedia, get_current_temperature]]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5c18f7b-6367-432e-9184-53bad6dcfb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 37.7749,\\n  \"longitude\": -122.4194\\n}'}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What is the weather in san francisco right now?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beed3983-14b0-4d2c-8794-12afb55c6110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_wikipedia', 'arguments': '{\\n  \"query\": \"langchain\"\\n}'}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What is langchain\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bce2385b-f8c0-426d-9dfa-3a89dd167e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1720f84-972f-4b02-b4f1-37ed3e22516e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 37.7749,\\n  \"longitude\": -122.4194\\n}'}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5da5a055-8d40-48ab-90ea-23a83d94b636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "103ebd07-8a2c-4034-921c-c05b8a2dc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adbbca41-6279-4b01-b483-c5ed0dbf17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29b4b5f4-3148-48f2-922f-35ebe56b20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2cc7fdb-f34a-4769-9641-4e67fa8c5636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.agent.AgentActionMessageLog"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5be19932-ce67-4f90-88cc-7d2abd462e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8228bd32-7d34-4ac5-a64f-168083408a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7b79df5-0fbc-4621-a9d3-acf78fa6eb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 28.7°C'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af8025b7-7658-4284-830d-4a85761423dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c8dc18f-8463-40e9-8073-dd6ebed66669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.agent.AgentFinish"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37d66c01-9a1c-4b22-88db-a265bd933a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17c11c21-c404-4ebe-a4fa-747a1678f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "297bb4b6-0780-43a5-a7ea-b5b8c4c0242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dffbd1d6-6090-4868-8e36-da1b868d7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d225b6ad-c1fb-4c52-8697-697aa7fd62df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 28.7°C'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39b85b4d-c2d3-47d9-bf36-d2611c79bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "027b0f7e-d60c-4a94-afa6-5ffc2ac34921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Sentence embedding\\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT\\'s sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT\\'s [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \\nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \\nAn alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.\\n\\n\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering, primarily used in communication with a text-to-text model and text-to-image model, is the process of structuring text that can be interpreted and understood by a generative AI model. Prompt engineering is enabled by in-context learning, defined as a model\\'s ability to temporarily learn from prompts. The ability for in-context learning is an emergent ability of large language models.\\nA prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", a short statement of feedback (for example, \"too verbose\", \"too formal\", \"rephrase again\", \"omit this word\") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". Prompt engineering may consist of a single prompt that includes a few examples for a model to learn from, such as \"maison -> house, chat -> cat, chien ->\", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "742d9ecc-72e1-4620-9839-a516d5d06e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"Hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ccd60ea-3c93-413e-88d6-61347782890d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f81f221-b69c-4cac-9150-fd78be735527",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0de3e7-2367-4cef-b3dd-efa69b701061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a353363e-27b8-440f-a8b7-31bc2e861a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b3737-eb4d-452a-b018-a1289f7f0d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcel_apicall",
   "language": "python",
   "name": "lcel_apicall"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
